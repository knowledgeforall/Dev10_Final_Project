{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3bef7d72-d4ff-45a5-9781-f4069b7686e8","showTitle":false,"title":""}},"outputs":[],"source":["def error_cb(err):\n","    \"\"\" The error callback is used for generic client errors. These\n","        errors are generally to be considered informational as the client will\n","        automatically try to recover from all errors, and no extra action\n","        is typically required by the application.\n","        For this example however, we terminate the application if the client\n","        is unable to connect to any broker (_ALL_BROKERS_DOWN) and on\n","        authentication errors (_AUTHENTICATION). \"\"\"\n","\n","    print(\"Client error: {}\".format(err))\n","    if err.code() == KafkaError._ALL_BROKERS_DOWN or \\\n","       err.code() == KafkaError._AUTHENTICATION:\n","        # Any exception raised from this callback will be re-raised from the\n","        # triggering flush() or poll() call.\n","        raise KafkaException(err)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2a2741dc-42f5-4b08-9fd5-8a22aa3db91a","showTitle":false,"title":""}},"outputs":[],"source":["from confluent_kafka import Consumer\n","from time import sleep\n","import uuid\n","from confluent_kafka import Producer, Consumer, KafkaError, KafkaException\n","import json\n","\n","\n","#KAFKA variables, Move to the OS variables or configuration\n","# This will work in local Jupiter Notebook, but in a databrick, hiding config.py is tougher. \n","confluentClusterName = \"stage3talent\"\n","confluentBootstrapServers = \"pkc-ldvmy.centralus.azure.confluent.cloud:9092\"\n","confluentTopicName = \"Group3Data\"\n","schemaRegistryUrl = \"https://psrc-gq7pv.westus2.azure.confluent.cloud\"\n","confluentApiKey = \"YHMHG7E54LJA55XZ\"\n","confluentSecret = \"/XYn+w3gHGMqpe9l0TWvA9FznMYNln2STI+dytyPqtZ9QktH0TbGXUqepEsJ/nR0\"\n","confluentRegistryApiKey = \"YHMHG7E54LJA55XZ\"\n","confluentRegistrySecret = \"/XYn+w3gHGMqpe9l0TWvA9FznMYNln2STI+dytyPqtZ9QktH0TbGXUqepEsJ/nR0\"\n","\n","\n","#Kakfa Class Setup.\n","c = Consumer({\n","    'bootstrap.servers': confluentBootstrapServers,\n","    'sasl.mechanism': 'PLAIN',\n","    'security.protocol': 'SASL_SSL',\n","    'sasl.username': confluentApiKey,\n","    'sasl.password': confluentSecret,# this will create a new consumer group on each invocation.\n","    'group.id': str(1),\n","    'auto.offset.reset': 'earliest',\n","    'enable.auto.commit': True,\n","    'error_cb': error_cb,\n","})\n","\n","c.subscribe(['Group3Data'])"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"afe75044-09e0-42b9-a363-5b30df78fc08","showTitle":false,"title":""}},"outputs":[],"source":["aString = {}\n","\n","kafkaList = []\n","\n","for i in range(1000):\n","    try:\n","        msg = c.poll(timeout=15)\n","        print(msg)\n","        if msg is None:\n","            break\n","        elif msg.error():\n","            print(\"Consumer error: {}\".format(msg.error()))\n","            break\n","        else:\n","            aString=json.loads('{}'.format(msg.value().decode('utf-8')))\n","            print('#' + str(i) + ' ' + str(aString))\n","            kafkaList.append(aString)\n","            c.commit(asynchronous=False)\n","    except Exception as e:\n","        print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"714ab0f2-ddbc-41a3-a6ce-fc9ac9100e2a","showTitle":false,"title":""}},"outputs":[],"source":["print(kafkaList)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b113f046-c439-40c1-8ec4-23607228a5dd","showTitle":false,"title":""}},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"52aa11fa-c64e-4221-a156-3b467b037644","showTitle":false,"title":""}},"outputs":[],"source":["df = pd.DataFrame(kafkaList)\n","\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9fe769a6-2c23-4f25-8ce6-2bc5ce1174a6","showTitle":false,"title":""}},"outputs":[],"source":["finaldf = spark.createDataFrame(df)\n","finaldf.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"310f89e9-8504-4d38-8e09-67b58e963113","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.types import DecimalType, StringType, FloatType\n","\n","output_df = finaldf \\\n","  .withColumn(\"DistrictName\", finaldf[\"DistrictName\"].cast(StringType())) \\\n","  .withColumn(\"GraduationPercentageRate\", finaldf[\"GraduationPercentageRate\"].cast(FloatType())) \\\n","  .withColumn(\"DropoutPercentageRate\", finaldf[\"DropoutPercentageRate\"].cast(FloatType())) \\\n","  .withColumn(\"FundingPerStudent\", finaldf[\"FundingPerStudent\"].cast(FloatType())) \\\n","  .withColumn(\"TotalEnrolled\", finaldf[\"TotalEnrolled\"].cast(FloatType())) \\\n","  .withColumn(\"MalesEnrolled\", finaldf[\"MalesEnrolled\"].cast(FloatType())) \\\n","  .withColumn(\"FemalesEnrolled\", finaldf[\"FemalesEnrolled\"].cast(FloatType())) \\\n","  .withColumn(\"Percentage of Minority Students\", finaldf[\"Percentage of Minority Students\"].cast(FloatType())) \\\n","  .withColumn(\"HouseholdIncome\", finaldf[\"HouseholdIncome\"].cast(FloatType())) \\\n","  .withColumn(\"FederallyFunded\", finaldf[\"FederallyFunded\"].cast(StringType())) "]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"91ca67c3-0d0c-4377-b61e-afacd66e30c3","showTitle":false,"title":""}},"outputs":[],"source":["output_df = output_df.withColumnRenamed(\"Percentage of Minority Students\", \"PercentageofMinorityStudents\")\n","output_df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3384e701-7668-42d5-809f-856c2e613650","showTitle":false,"title":""}},"outputs":[],"source":["database = \"Capstone-Group3\"\n","table = \"dbo.nystatedistricts\"\n","user = \"stanleyperez\"\n","password  = \"\"\n","server = \"gen10-data-fundamentals-22-05-sql-server.database.windows.net\"\n","\n","output_df.write.format('jdbc').option(\"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\") \\\n","    .mode(\"overwrite\") \\\n","    .option(\"dbtable\", table) \\\n","    .option(\"user\", user) \\\n","    .option(\"password\", password) \\\n","    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n","    .save()"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"districtdata-consumer","notebookOrigID":1123985657305787,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
